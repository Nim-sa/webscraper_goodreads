{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe373267",
   "metadata": {},
   "source": [
    "# üìö Goodreads Book Scraper (100 Pages)\n",
    "\n",
    "A Python-based web scraper that collects book data from Goodreads' \"Best Books Ever\" list across 100 pages.  \n",
    "Extracted information includes **Title**, **Author**, and **Average Rating**, saved to a clean CSV for analysis or portfolio use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ecc145",
   "metadata": {},
   "source": [
    "## üîç Features\n",
    "- Scrapes 100 pages from Goodreads' book list\n",
    "- Extracts title, author, and rating info\n",
    "- Cleans and structures the data\n",
    "- Saves results to CSV\n",
    "- Performs basic analysis (top-rated books, top authors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee92e980",
   "metadata": {},
   "source": [
    "### Install Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848b983e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests beautifulsoup4 pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859ba2c8",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbc12b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163a1a76",
   "metadata": {},
   "source": [
    "### Define the Scraper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c971043",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_goodreads_books(pages=100):\n",
    "    base_url = \"https://www.goodreads.com/list/show/1.Best_Books_Ever?page=\"\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    \n",
    "    all_books = []\n",
    "\n",
    "    for page in range(1, pages + 1):\n",
    "        url = base_url + str(page)\n",
    "        print(f\"Scraping page {page}...\")\n",
    "\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers, timeout=15)\n",
    "            response.raise_for_status()\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\" Failed to fetch page {page}: {e}\")\n",
    "            time.sleep(5)\n",
    "            continue\n",
    "\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        book_rows = soup.find_all(\"tr\", itemtype=\"http://schema.org/Book\")\n",
    "\n",
    "        for book in book_rows:\n",
    "            try:\n",
    "                title = book.find(\"a\", class_=\"bookTitle\").text.strip()\n",
    "                author = book.find(\"a\", class_=\"authorName\").text.strip()\n",
    "                rating = book.find(\"span\", class_=\"minirating\").text.strip()\n",
    "                all_books.append({\n",
    "                    \"Title\": title,\n",
    "                    \"Author\": author,\n",
    "                    \"Rating Info\": rating\n",
    "                })\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        time.sleep(2)  # Be kind to the server\n",
    "\n",
    "    return pd.DataFrame(all_books)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2f1b1b",
   "metadata": {},
   "source": [
    "### Run the Scraper for All 100 Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb11377",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books = scrape_goodreads_books(pages=100)\n",
    "df_books.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc35bb9",
   "metadata": {},
   "source": [
    "### Clean the Rating Info Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcf4bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_rating(text):\n",
    "    try:\n",
    "        return float(text.split(\" \")[0])\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "df_books[\"Rating\"] = df_books[\"Rating Info\"].apply(extract_rating)\n",
    "df_books = df_books.drop(columns=[\"Rating Info\"])\n",
    "df_books.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320c8f05",
   "metadata": {},
   "source": [
    "### Analyze the Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97af9ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books[\"Author\"].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d580ece",
   "metadata": {},
   "source": [
    "### Plot Top-Rated Books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c2dff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "top_books = df_books.sort_values(by=\"Rating\", ascending=False).head(10)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(top_books[\"Title\"], top_books[\"Rating\"], color='skyblue')\n",
    "plt.xlabel(\"Rating\")\n",
    "plt.title(\"Top 10 Highest Rated Books\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc27662",
   "metadata": {},
   "source": [
    "### Save the scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e93e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books.to_csv(\"cleaned_goodreads_books.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
